{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c95f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682115c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "from vesuvius.data.vesuvius_train import VesuviusTrainDataset\n",
    "from vesuvius.data.subset_with_transform import SubsetWithTransform\n",
    "\n",
    "# Transforms\n",
    "from vesuvius.transforms.get_transforms import get_transformations\n",
    "\n",
    "# Model / training\n",
    "from vesuvius.models.unet3d_small import SmallUNet3D\n",
    "from vesuvius.losses import DiceBCELoss\n",
    "from vesuvius.training.train_loop import train_loop\n",
    "\n",
    "# Visualization\n",
    "from vesuvius.visualization.prediction_viz import plot_prediction_triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2a055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /Users/chamu/vesuvius-scroll-detection/data/raw/vesuvius\n"
     ]
    }
   ],
   "source": [
    "# Root folder path\n",
    "ROOT = Path(\"~/vesuvius-scroll-detection/data/raw/vesuvius\").expanduser()\n",
    "\n",
    "print(\"ROOT:\", ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a77d73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device selection\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afc3000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 806\n",
      "Train subset: 686\n",
      "Val subset: 120\n"
     ]
    }
   ],
   "source": [
    "# Load dataset + split\n",
    "ds = VesuviusTrainDataset(ROOT)\n",
    "print(\"Dataset size:\", len(ds))\n",
    "\n",
    "val_fraction = 0.15\n",
    "seed = 0\n",
    "\n",
    "n_total = len(ds)\n",
    "n_val = max(1, int(val_fraction * n_total))\n",
    "n_train = n_total - n_val\n",
    "\n",
    "g = torch.Generator().manual_seed(seed)\n",
    "train_subset, val_subset = random_split(ds, [n_train, n_val], generator=g)\n",
    "\n",
    "print(\"Train subset:\", len(train_subset))\n",
    "print(\"Val subset:\", len(val_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37294ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATCH: (32, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "# Define patch + build transforms\n",
    "PATCH = (32, 96, 96)\n",
    "print(\"PATCH:\", PATCH)\n",
    "\n",
    "# Deterministic (val/test)\n",
    "val_tf, train_tf = get_transformations(\n",
    "    crop_size=PATCH,\n",
    "    use_random_crop_for_train=True,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    use_flips=True,\n",
    "    use_intensity_jitter=True,\n",
    "    use_gaussian_noise=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f6f241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch: torch.Size([1, 1, 32, 96, 96]) torch.Size([1, 1, 32, 96, 96]) sid: ('1820528268',)\n",
      "Mask unique: tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Wrap datasets\n",
    "train_ds = SubsetWithTransform(train_subset, transform=train_tf)\n",
    "val_ds   = SubsetWithTransform(val_subset, transform=val_tf)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "imgs, masks, sids = next(iter(train_loader))\n",
    "print(\"Train batch:\", imgs.shape, masks.shape, \"sid:\", sids)\n",
    "print(\"Mask unique:\", torch.unique(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "801d8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model loss + optimizer\n",
    "model = SmallUNet3D(in_channels=1, base_channels=16).to(device)\n",
    "\n",
    "loss_fn = DiceBCELoss(\n",
    "    w_bce=0.5,\n",
    "    w_dice=0.5,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58bb9a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train loop\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m history = \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vesuvius-scroll-detection/src/vesuvius/training/train_loop.py:35\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(model, train_loader, val_loader, loss_fn, optimizer, device, epochs, log_every, threshold)\u001b[39m\n\u001b[32m     32\u001b[39m hist = TrainHistory(train_loss=[], val_loss=[], dice=[])\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     tr = \u001b[43mtrain_epoch_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     va, mets = validate_epoch_3d(model, val_loader, loss_fn, device, threshold=threshold)\n\u001b[32m     38\u001b[39m     hist.train_loss.append(\u001b[38;5;28mfloat\u001b[39m(tr))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vesuvius-scroll-detection/src/vesuvius/training/train_epoch_3d.py:28\u001b[39m, in \u001b[36mtrain_epoch_3d\u001b[39m\u001b[34m(model, train_loader, loss_fn, optimizer, device)\u001b[39m\n\u001b[32m     25\u001b[39m     optimizer.step()\n\u001b[32m     27\u001b[39m     bs = imgs.size(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     running_loss += \u001b[38;5;28mfloat\u001b[39m(\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) * bs\n\u001b[32m     29\u001b[39m     n_samples += bs\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m running_loss / \u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, n_samples)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "history = train_loop(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    epochs=40,\n",
    "    log_every=5,\n",
    "    threshold=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1867bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(history.train_loss, label=\"train\")\n",
    "plt.plot(history.val_loss, label=\"val\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(history.dice)\n",
    "plt.title(\"Dice\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(history.train_loss)\n",
    "plt.title(\"Train loss (zoomed)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual sanity check\n",
    "plot_prediction_triplet(\n",
    "    model=model,\n",
    "    loader=val_loader,\n",
    "    device=device,\n",
    "    threshold=0.3,\n",
    "    title_prefix=\"Augmented model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf111bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold sensitivity\n",
    "for thr in [0.2, 0.3, 0.5, 0.7]:\n",
    "    plot_prediction_triplet(\n",
    "        model=model,\n",
    "        loader=val_loader,\n",
    "        device=device,\n",
    "        threshold=thr,\n",
    "        title_prefix=f\"thr={thr}\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
